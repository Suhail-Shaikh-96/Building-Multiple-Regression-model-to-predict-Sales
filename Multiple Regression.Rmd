---
title: "Multiple Regression"
author: "Suhail Shaikh"
date: "12/22/2019"
output: html_document
---

Q.1)Build an exhaustive multiple regression model to predict sales Provide a thoughtful and thorough explanation of the findings of this model. 
```{r a}

setwd("C:\\Users\\shaik\\Desktop\\projects data mining\\General\\Multiple Regression")
load("Multiple Regression.RData")

str(promos)
head(promos)

#Step1 -Checking Normality of dependent Variable
library(psych)
summary(promos$sales)
describe(promos$sales)
#Here in sales mean is approximately equal to median and sd is very small compared to the mean Hence sales seems to have normally distributed. Lets check with the plots
hist(promos$sales,probability=T,col=c("steelblue", "red"))
lines(density(promos$sales),col="black",lwd=3)
#The histogram shows that the sales is normally distributed

boxplot(promos$sales)
#Boxplot shows that there are no outliers in the variable accuracy but the sales is slightly left skewed

#Hence from all above the sales is roughly normaly distributed 

#step2- Checking linear relationship between IVs and DVS
cor.test(promos$sales, promos$online)
# cor 
# 0.7626416
#High  positive correlation
plot(promos$sales, promos$online, pch=16, col="red") 


cor.test(promos$sales, promos$paper) 
# cor 
# 0.20
#There is no correlation of paper with sales
plot(promos$sales, promos$paper, pch=16, col="red") 

cor.test(promos$sales, promos$in_store) 
# cor 
# 0.5877
#There is positive correlation of in_store with sales
plot(promos$sales, promos$in_store, pch=16, col="red") 

#Step 3- multiple regression model

model1<-lm(sales ~ online+paper+in_store+region, data=promos)
model1

summary(model1) 


#Findings from model1
#The adjusted R square is 0.8885 i.e 88.85% of variance in sales is explained by the model. 
#The variables online and in_store are significant with sales as have p-values less than 0.05
#One unit increase in online increase the sales by 0.044408  units.
#One unit increase in in_store increases the sales by 0.187849 units

#Since this model has some insignificat variables like region and paper we have to remove them

```



Q.2)Build a new model that is only based on the Independent Variables that are "good" predictors. Explain your findings
```{r b}


#Since this model developed in question 1 has some insignificat variables (from summary of model checking p values)like region and paper we have to remove them

#lets select variables online and in_store in model as they are significant i.e have p-value less than 0.05 in summary(model1)
model2<-lm(sales ~ online+in_store, data=promos)
model2
summary(model2)

summary(model2)$adj.r.squared-summary(model1)$adj.r.squared
#The adjusted R-square value is actually decreasing by 0.1% but we still have to remove the variables region and paper as they are not significant with the sales and are violating the assumptions of the regression model

#Findings from model2
#The adjusted R square is 0.8868 
#The variables online and in_store are significant with sales as have p-values less than 0.05
#One unit increase in online increase the sales by 0.044353  units.
#One unit increase in in_store increases the sales by 0.186455 units


```


Q.3) Perform a regression diagnosis. What concerns do you have with your model, and explain how would you address them?
```{r c}

#Run diagnostic tests
par(mfrow=c(2,2))
plot(model2)

outliers= c(5,64,75)
promos1<-promos[-outliers,]
model2.1<-lm(sales ~ online+in_store, data=promos1)

summary(model2.1)

summary(model2.1)$adj.r.squared-summary(model2)$adj.r.squared
#The adjusted R-square value is actually increased by 3% after removing the outliers the outliers are removed as in QQ plotit was not showing the approx diagonal line and hence was less normal due to the outliers
#After removing the outliers QQ plot can be  considered to be normal


car::vif(model2.1)
#there is no problem of multicollinearity here. The multicollinearity is checked because while developing regression model we assume that there is no collinearity among the independent variables.
#If the vif is greater than 10 there is multicollinearity and independent variables are not completely independent which affects the model. Hence multicollinearity is tested in diagnostics.


#Findings from model
#The adjusted R square is increased to 0.918
#The variables online and instore are significant woith sales
#One unit increase in online increase the sales by 0.042 units.
#One unit increase in in_store increases the sales by 0.1945 units


```
